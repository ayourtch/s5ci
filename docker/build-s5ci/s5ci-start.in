#!/bin/sh


. /secrets/env-vars.env

# export STORAGE_USER="{{ACTUAL_STORAGE_USER}}"
# export STORAGE_HOST="{{ACTUAL_STORAGE_HOST}}"
# export STORAGE_DIR="jobs"

# export GERRIT_HOST="{{ACTUAL_GERRIT_HOST}}"
# export LOG_DIR="/local/logs"
# export TIMELINE_LOG="${LOG_DIR}/timeline.log"
# export INITIAL_RSYNC_LOG="${LOG_DIR}/initial-rsync.log"
# export BACK_RSYNC_LOG="${LOG_DIR}/back-rsync.log"
# export DB_REBUILD_LOG="${LOG_DIR}/db-rebuild.log"

# make directory for logs
mkdir ${LOG_DIR}

echo "$(date): EXECSTART" >>${TIMELINE_LOG}
mkdir -p ~/.ssh

export NETWORK_LOG="${LOG_DIR}/network.log"
date >>${NETWORK_LOG}
ip addr >>${NETWORK_LOG}
ip route >>${NETWORK_LOG}
curl http://s5ci-images.myvpp.net >>${NETWORK_LOG}
echo "end of net" >>${NETWORK_LOG}

while true; do curl http://s5ci-images.myvpp.net >> ${INITIAL_RSYNC_LOG} && break; date; sleep 1; done
echo "$(date): connectivity is ok" >>${TIMELINE_LOG}

# pin the ssh hosts
echo "$(date): scan SSH key for storage" >>${TIMELINE_LOG}
ssh-keyscan -H -p 23 ${STORAGE_HOST} >>~/.ssh/known_hosts
ssh-keyscan -H -p 23 ${LOGS_HOST} >>~/.ssh/known_hosts

echo "$(date): scan SSH key for gerrit" >>${TIMELINE_LOG}
ssh-keyscan -H -p 29418 ${GERRIT_HOST} >>~/.ssh/known_hosts
# add the test host as well
ssh-keyscan -H -p 29418 testgerrit.myvpp.net >>~/.ssh/known_hosts

# export S5CI_CONFIG_PATH="/local/s5ci-configs/config.yaml"
# export S5CI_CONFIG_CLONE_URL="http://testgerrit.myvpp.net/r/s5ci-pilot"
echo "$(date): clone s5ci config from ${S5CI_CONFIG_CLONE_URL}" >>${TIMELINE_LOG}
(cd /local; git clone ${S5CI_CONFIG_CLONE_URL} s5ci-configs)

if [ -f /local/cluster-id ]; then
	export CLUSTER_ID=$(cat /local/cluster-id)
else
	echo $(hostname) >/local/cluster-id
	export CLUSTER_ID=$(cat /local/cluster-id)
fi
echo "$(date): CLUSTER_ID value set to: ${CLUSTER_ID}" >>${TIMELINE_LOG}

# populate the jobs data from the storage
echo "$(date): initial rsync data from storage" >>${TIMELINE_LOG}
if [ -f /local/initial-rsync-filter ]; then
        echo "$(date): /local/initial-rsync-filter found" >>${TIMELINE_LOG}
	rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --filter='merge /local/initial-rsync-filter' ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
else
        echo "$(date): /local/initial-rsync-filter not found - doing full rsync" >>${TIMELINE_LOG}
        rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
fi


# re-copy possibly updated static html to upstream
echo "$(date): copy html to /local/html" >>${TIMELINE_LOG}
cp -r /var/www/html/html /local/html


export NOMAD_AGENT_LOG="${LOG_DIR}/nomad-agent.log"
export NOMAD_LOG="${LOG_DIR}/nomad.log"
if [ -f /secrets/nomad-agent.hcl ]; then
        echo "$(date): nomad-agent.hcl found, starting nomad" >>${TIMELINE_LOG}
	nomad agent -config /secrets/nomad-agent.hcl >${NOMAD_AGENT_LOG} 2>${NOMAD_AGENT_LOG} &
        echo "$(date): waiting to join the cluster" >>${TIMELINE_LOG}
        while true; do nomad status >> ${NOMAD_LOG} && break; date >>${NOMAD_LOG}; sleep 1; done
        echo "$(date): joined the cluster" >>${TIMELINE_LOG}
        echo "Run nomad status" >>${NOMAD_LOG}
	nomad status >>${NOMAD_LOG}
else
        echo "$(date): nomad-agent.hcl not found, skipped nomad tasks" >>${TIMELINE_LOG}
fi

while [ -f /secrets/startup-pause.txt ]; do
	echo "startup-pause.txt synchronization ... " >>"${INITIAL_RSYNC_LOG}"
	if [ -f /local/initial-rsync-filter ]; then
		echo "$(date): /local/initial-rsync-filter found" >>${TIMELINE_LOG}
		rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --filter='merge /local/initial-rsync-filter' ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
	else
		echo "$(date): /local/initial-rsync-filter not found - doing full rsync" >>${TIMELINE_LOG}
		rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
	fi
        echo "$(date): /secrets/startup-pause.txt exists - wait 30 sec ..." >>${TIMELINE_LOG}
	sleep 30
done

#
# stop the currently active s5ci from spawning new jobs
#
ACTIVE_ALLOC_ID=$(cat /local/jobs/heartbeat.json  | jq -r .nomad_alloc_id)
nomad exec ${ACTIVE_ALLOC_ID} touch /secrets/shutdown-pause.txt
ACTIVE_S5CI_PID=$(nomad exec -t=false ${ACTIVE_ALLOC_ID} ps -ef | grep s5ci | egrep -e '/config.yaml$' | awk '{ print $2 }')
nomad exec ${ACTIVE_ALLOC_ID} kill ${ACTIVE_S5CI_PID}

# stop the poll loops in the already running instances (heartbeat within 120 sec) with the same cluster id
INSTANCES=$(find /local/jobs/updatedb/ -name heartbeat.json -exec cat {} \; | jq -r "select(.cluster_id==\"${CLUSTER_ID}\")|select((.rsync_timestamp|tonumber) > now-120)|.nomad_alloc_id")
for ACTIVE_ALLOC_ID in $INSTANCES; do
	echo "$(date): instance ${inst} has the same cluster id, stopping poll loop..." >>${TIMELINE_LOG}
	nomad exec ${ACTIVE_ALLOC_ID} touch /secrets/shutdown-pause.txt
	ACTIVE_S5CI_PID=$(nomad exec -t=false ${ACTIVE_ALLOC_ID} ps -ef | grep s5ci | egrep -e '/config.yaml$' | awk '{ print $2 }')
	nomad exec ${ACTIVE_ALLOC_ID} kill ${ACTIVE_S5CI_PID}
done

# sync again, after we have stopped the currently active s5ci
if [ -f /local/initial-rsync-filter ]; then
        echo "$(date): /local/initial-rsync-filter found" >>${TIMELINE_LOG}
	rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --filter='merge /local/initial-rsync-filter' ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
else
        echo "$(date): /local/initial-rsync-filter not found - doing full rsync" >>${TIMELINE_LOG}
        rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
fi

echo "$(date): s5ci database rebuild" >>${TIMELINE_LOG}
# put the transaction mode to WAL for somewhat better performance
echo PRAGMA journal_mode=WAL | sqlite3 /s5ci/db/s5ci.sqlite3
RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/s5ci -c ${S5CI_CONFIG_PATH} rebuild-database >>${DB_REBUILD_LOG}
# mark active as failed - and if they are alive, they will come back
echo "$(date): marking still active jobs as failed and doing full sync back" >>${TIMELINE_LOG}
RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/s5ci -c ${S5CI_CONFIG_PATH} mark-active-as-failed >>${DB_REBUILD_LOG}
# do the full sync to the store
rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --exclude workspace /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
echo PRAGMA journal_mode=DELETE | sqlite3 /s5ci/db/s5ci.sqlite3

#
# Do optional adjustments
#

if [ -f /local/startup-exec ]; then
        echo "$(date): /local/startup-exec found - executing" >>${TIMELINE_LOG}
        bash -c /local/startup-exec >>"${LOG_DIR}/startup-exec.log"
else
        echo "$(date): /secrets/startup-exec not found - not executing" >>${TIMELINE_LOG}
fi

echo "$(date): starting background back-sync loop" >>${TIMELINE_LOG}
setsid -w rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive /local/html ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}

while (true); do
	sleep 1
        echo "$(date): rsync back" >>${BACK_RSYNC_LOG}
	# rsync a tiny file upstream each second so people know we are alive
        printf '{ "nomad_alloc_id": "%s", "rsync_timestamp": "%s", "nomad_job_id": "%s"}' ${NOMAD_ALLOC_ID} $(date '+%s') ${NOMAD_JOB_ID}> /local/jobs/heartbeat.json
	UPDATE_DIR="/local/jobs/updatedb/$(hostname)"
	mkdir -p ${UPDATE_DIR} || true
        printf '{ "nomad_alloc_id": "%s", "rsync_timestamp": "%s", "nomad_job_id": "%s", "cluster_id": "%s"}' ${NOMAD_ALLOC_ID} $(date '+%s') "${NOMAD_JOB_ID}" "${CLUSTER_ID} > ${UPDATE_DIR}/heartbeat.json

	# prepare the file list of jobs that changed status in the last 10 minutes
	/usr/local/bin/go-s5ci -c ${S5CI_CONFIG_PATH} list-jobs -r /tmp/s5ci-rsync-list -t 600 -e $(hostname)
	if [ -f /local/back-sync-adjust-list ]; then
		bash -c /local/back-sync-adjust-list >>${BACK_RSYNC_LOG}
	fi
	cp /tmp/s5ci-rsync-list ${UPDATE_DIR}/rsync-filter.txt

	# rsync the html UI and data, do not delete
	# rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --exclude workspace /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}

	rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --filter='merge /tmp/s5ci-rsync-list' /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
	if [ -f /local/back-sync-exec ]; then
		bash -c /local/back-sync-exec >>${BACK_RSYNC_LOG}
	fi
done &

BACKSYNC_PID=$!


### sync the jobs from other hosts which were in a drain mode
while (true); do
	# get the list of jobs either still running or just finished, on other hosts
	go-s5ci -c ${S5CI_CONFIG_PATH} list-jobs -t 600 -r /tmp/s5ci-rsync-other-hosts -n $(hostname)
	# rsync the list of jobs we know are maybe still sitting on other hosts
	rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --filter='merge /tmp/s5ci-rsync-other-hosts' ${STORAGE_USER}@${STORAGE_HOST}: /local/ 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
	# re-import the data from yaml files into the database
	go-s5ci -c ${S5CI_CONFIG_PATH} list-jobs -t 600 -n $(hostname) -u /local/jobs
	# sleep 5 minutes
	sleep 300

done &
DRAINSYNC_PID=$!

#
# this part runs with signals intercepted, for cleanup
#


echo "$(date): EXECOK: S5CI startup finished, now run" >>${TIMELINE_LOG}

trap sigint INT
trap '' PIPE
trap '' HUP
trap cleanup QUIT
trap cleanup ABRT
trap cleanup TERM

sigint()
{
	echo "$(date): got SIGINT" >>${TIMELINE_LOG}
}

cleanup()
{
	echo "$(date): got SIGTERM" >>${TIMELINE_LOG}
        echo "Caught signal, cleaning up"
        echo "Done cleanup"
}


# execute the meta-s5ci
RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/go-s5ci -c ${META_S5CI_CONFIG_PATH} 2>>${META_S5CI_LOG} >>${META_S5CI_LOG} &

# execute the s5ci. 
RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/go-s5ci -c ${S5CI_CONFIG_PATH}

# kill the background sync
kill $BACKSYNC_PID
kill $DRAINSYNC_PID

# if instructed - wait
while [ -f /secrets/shutdown-pause.txt ]; do
        echo "$(date): /secrets/shutdown-pause.txt exists - wait 30 sec..." >>${TIMELINE_LOG}
	sleep 30
	# prepare the file list of jobs that changed status in the last 10 minutes
	/usr/local/bin/go-s5ci -c ${S5CI_CONFIG_PATH} list-jobs -r /tmp/s5ci-rsync-list -t 600 -e $(hostname) --drain-mode
	if [ -f /local/back-sync-adjust-list ]; then
		bash -c /local/back-sync-adjust-list >>${BACK_RSYNC_LOG}
	fi

	rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --filter='merge /tmp/s5ci-rsync-list' /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
	if [ -f /local/back-sync-exec ]; then
		bash -c /local/back-sync-exec >>${BACK_RSYNC_LOG}
	fi
done

echo "$(date): S5CI finished, status: $?" >>${TIMELINE_LOG}
echo "$(date): final rsync"
# prepare file list of the final sync
/usr/local/bin/go-s5ci -c ${S5CI_CONFIG_PATH} list-jobs -r /tmp/s5ci-rsync-list -t 600 -e $(hostname) --drain-mode
if [ -f /local/back-sync-adjust-list ]; then
	bash -c /local/back-sync-adjust-list >>${BACK_RSYNC_LOG}
fi
# sync the files
setsid rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --max-delete=-1 --filter='merge /tmp/s5ci-rsync-list' --recursive /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
echo "$(date): final rsync finished" >>${TIMELINE_LOG}

# the empty cycle in the end
for i in $(seq 60 -1 1); do
	echo "$(date): winding down, $i sec remaining">>${TIMELINE_LOG}
	sleep 1
done

