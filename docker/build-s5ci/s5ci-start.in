#!/bin/sh


. /secrets/env-vars.env
. /secrets/early-exec-once.env

# export STORAGE_USER="{{ACTUAL_STORAGE_USER}}"
# export STORAGE_HOST="{{ACTUAL_STORAGE_HOST}}"
# export STORAGE_DIR="jobs"

# export GERRIT_HOST="{{ACTUAL_GERRIT_HOST}}"
# export LOG_DIR="/local/logs"
# export TIMELINE_LOG="${LOG_DIR}/timeline.log"
# export INITIAL_RSYNC_LOG="${LOG_DIR}/initial-rsync.log"
# export BACK_RSYNC_LOG="${LOG_DIR}/back-rsync.log"
# export DB_REBUILD_LOG="${LOG_DIR}/db-rebuild.log"

# make directory for logs
mkdir ${LOG_DIR}

echo "$(date): EXECSTART" >>${TIMELINE_LOG}
mkdir -p ~/.ssh

export NETWORK_LOG="${LOG_DIR}/network.log"
date >>${NETWORK_LOG}
ip addr >>${NETWORK_LOG}
ip route >>${NETWORK_LOG}
curl http://s5ci-images.myvpp.net >>${NETWORK_LOG}
echo "end of net" >>${NETWORK_LOG}

if [ -f /local/nginx-nomad.conf ]; then
	echo "$(date): copy nginx nomad config" >>${TIMELINE_LOG}
	cp /local/nginx-nomad.conf /etc/nginx/modules-enabled/
	# one worker is enough
	sed -i -e 's/worker_processes auto/worker_processes 1/' /etc/nginx/nginx.conf
	service nginx restart
fi

while true; do curl http://s5ci-images.myvpp.net >> ${INITIAL_RSYNC_LOG} && break; date; sleep 1; done
echo "$(date): connectivity is ok" >>${TIMELINE_LOG}

# pin the ssh hosts
echo "$(date): scan SSH key for storage" >>${TIMELINE_LOG}
ssh-keyscan -H -p 23 ${STORAGE_HOST} >>~/.ssh/known_hosts
ssh-keyscan -H -p 23 ${LOGS_HOST} >>~/.ssh/known_hosts

echo "$(date): scan SSH key for gerrit" >>${TIMELINE_LOG}
ssh-keyscan -H -p 29418 ${GERRIT_HOST} >>~/.ssh/known_hosts
# add the test host as well
ssh-keyscan -H -p 29418 testgerrit.myvpp.net >>~/.ssh/known_hosts

# export S5CI_CONFIG_PATH="/local/s5ci-configs/config.yaml"
# export S5CI_CONFIG_CLONE_URL="http://testgerrit.myvpp.net/r/s5ci-pilot"
echo "$(date): clone s5ci config from ${S5CI_CONFIG_CLONE_URL}" >>${TIMELINE_LOG}
(cd /local; git clone ${S5CI_CONFIG_CLONE_URL} s5ci-configs)

if [ -f /local/cluster-id ]; then
	export CLUSTER_ID=$(cat /local/cluster-id)
else
	echo $(hostname) >/local/cluster-id
	export CLUSTER_ID=$(cat /local/cluster-id)
fi
echo "$(date): CLUSTER_ID value set to: ${CLUSTER_ID}" >>${TIMELINE_LOG}

# populate the jobs data from the storage
echo "$(date): initial rsync data from storage" >>${TIMELINE_LOG}
if [ -f /local/initial-rsync-filter ]; then
        echo "$(date): /local/initial-rsync-filter found" >>${TIMELINE_LOG}
	rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --filter='merge /local/initial-rsync-filter' ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
else
        echo "$(date): /local/initial-rsync-filter not found - doing full rsync" >>${TIMELINE_LOG}
        rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
fi


# re-copy possibly updated static html to upstream
echo "$(date): copy html to /local/html" >>${TIMELINE_LOG}
cp -r /var/www/html/html /local/html

echo "Run nomad status" >>${NOMAD_LOG}
nomad status >>${NOMAD_LOG}

while [ -f /secrets/startup-pause.txt ]; do
	echo "startup-pause.txt synchronization ... " >>"${INITIAL_RSYNC_LOG}"
	if [ -f /local/initial-rsync-filter ]; then
		echo "$(date): /local/initial-rsync-filter found" >>${TIMELINE_LOG}
		rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --filter='merge /local/initial-rsync-filter' ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
	else
		echo "$(date): /local/initial-rsync-filter not found - doing full rsync" >>${TIMELINE_LOG}
		rsync -avz --progress -e 'ssh -p23 -i/secrets/s5ci-key' --recursive ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}"
	fi
	echo "Initial rsync ret code: $?" >>${TIMELINE_LOG}
        echo "$(date): /secrets/startup-pause.txt exists - wait 30 sec ..." >>${TIMELINE_LOG}
	sleep 30
done

# rebuild the database from the downloaded pieces
echo "$(date): s5ci database rebuild" >>${TIMELINE_LOG}
# put the transaction mode to WAL for somewhat better performance
echo PRAGMA journal_mode=WAL | sqlite3 /s5ci/db/s5ci.sqlite3
RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/go-s5ci -c ${S5CI_CONFIG_PATH} rebuild-database >>${DB_REBUILD_LOG}
# mark active as failed - and if they are alive, they will come back
echo "$(date): marking still active jobs as failed" >>${TIMELINE_LOG}
RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/go-s5ci -c ${S5CI_CONFIG_PATH} mark-active-as-failed >>${DB_REBUILD_LOG}

# the above does the full regenerate of html, so not needed...
# echo "$(date): regenerate all html" >>${TIMELINE_LOG}
# RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/s5ci -c ${S5CI_CONFIG_PATH} regenerate-html >>${DB_REBUILD_LOG}
# do the full sync to the store
echo "$(date): doing full sync back" >>${TIMELINE_LOG}
rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --exclude workspace /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
echo "Back rsync ret code: $?" >>${TIMELINE_LOG}
echo PRAGMA journal_mode=DELETE | sqlite3 /s5ci/db/s5ci.sqlite3

#
# stop the currently active s5ci from spawning new jobs
#
# ACTIVE_ALLOC_ID=$(cat /local/jobs/heartbeat.json  | jq -r .nomad_alloc_id)
# nomad exec ${ACTIVE_ALLOC_ID} touch /secrets/shutdown-pause.txt
# ACTIVE_S5CI_PID=$(nomad exec -t=false ${ACTIVE_ALLOC_ID} ps -ef | grep s5ci | egrep -e '/config.yaml$' | awk '{ print $2 }')
# nomad exec ${ACTIVE_ALLOC_ID} kill ${ACTIVE_S5CI_PID}

echo "Active instance dir:" >>${TIMELINE_LOG}
ls -al /local/jobs/updatedb/ >>${TIMELINE_LOG}
(find /local/jobs/updatedb/ -name heartbeat.json -exec cat {} \; -exec printf "\n" \; >>${TIMELINE_LOG}
# stop the poll loops in the already running instances (heartbeat within 120 sec) with the same cluster id
HOSTNAME=$(hostname)
INSTANCES=$(find /local/jobs/updatedb/ -name heartbeat.json -exec cat {} \; | jq -r "select(.cluster_id==\"${CLUSTER_ID}\")|select((.rsync_timestamp|tonumber) > now-120)|select(.hostname!=\"${HOSTNAME}\")|.nomad_alloc_id")

for ACTIVE_ALLOC_ID in $INSTANCES; do
	echo "$(date): instance ${ACTIVE_ALLOC_ID} has the same cluster id, stop poll loop there..." >>${TIMELINE_LOG}
	nomad exec ${ACTIVE_ALLOC_ID} touch /secrets/shutdown-pause.txt
	# let the jobs kill themselves when there is no active tasks remaining
	nomad exec ${ACTIVE_ALLOC_ID} touch /secrets/nomad-self-shutdown.txt
	ACTIVE_S5CI_PID=$(nomad exec -t=false ${ACTIVE_ALLOC_ID} ps -ef | grep s5ci | egrep -e '/config.yaml$' | awk '{ print $2 }')
	nomad exec ${ACTIVE_ALLOC_ID} kill ${ACTIVE_S5CI_PID}
done


#
# Do optional adjustments
#

if [ -f /local/startup-exec ]; then
        echo "$(date): /local/startup-exec found - executing" >>${TIMELINE_LOG}
        bash -c /local/startup-exec >>"${LOG_DIR}/startup-exec.log"
else
        echo "$(date): /secrets/startup-exec not found - not executing" >>${TIMELINE_LOG}
fi

echo "$(date): starting background back-sync loop" >>${TIMELINE_LOG}
setsid -w rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive /local/html ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}

while (true); do
	sleep 1
        echo "$(date): rsync back" >>${BACK_RSYNC_LOG}
	# rsync a tiny file upstream each second so people know we are alive
	printf '{ "nomad_alloc_id": "%s", "rsync_timestamp": "%s", "nomad_job_name": "%s", "hostname": "%s"}' ${NOMAD_ALLOC_ID} $(date '+%s') "${NOMAD_JOB_NAME}" "$(hostname)" > /local/jobs/heartbeat.json
	UPDATE_DIR="/local/jobs/updatedb/$(hostname)"
	mkdir -p ${UPDATE_DIR} || true
	printf '{ "nomad_alloc_id": "%s", "rsync_timestamp": "%s", "nomad_job_name": "%s", "cluster_id": "%s", "hostname": "%s"}' ${NOMAD_ALLOC_ID} $(date '+%s') "${NOMAD_JOB_NAME}" "${CLUSTER_ID}" "$(hostname)" > ${UPDATE_DIR}/heartbeat.json

	# prepare the file list of jobs that changed status in the last 10 minutes
	/usr/local/bin/go-s5ci -c ${S5CI_CONFIG_PATH} list-jobs -i /tmp/s5ci-idx-rsync-list -r /tmp/s5ci-rsync-list -d /tmp/s5ci-db-rsync-list -j /tmp/s5ci-updated-jobs.json -y /tmp/s5ci-updated-jobs.yaml -t 600 -e $(hostname)
	if [ -f /local/back-sync-adjust-list ]; then
		bash -c /local/back-sync-adjust-list >>${BACK_RSYNC_LOG}
	fi
	cp /tmp/s5ci-rsync-list ${UPDATE_DIR}/rsync-filter.txt
	cp /tmp/s5ci-db-rsync-list ${UPDATE_DIR}/rsync-db-filter.txt
	cp /tmp/s5ci-updated-jobs.json ${UPDATE_DIR}/updated-jobs.json
	cp /tmp/s5ci-updated-jobs.yaml ${UPDATE_DIR}/updated-jobs.yaml

	# rsync the html UI and data, do not delete
	# rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --exclude workspace /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
	while [ -f /secrets/upstream-sync-pause.txt ]; do
		echo "$(date): /secrets/upstream-sync-pause.txt exists - wait 30 sec..." >>${BACK_RSYNC_LOG}
		sleep 30
	done

	rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --filter='merge /tmp/s5ci-rsync-list' /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
	echo "RSYNC ret code: $?" >>${BACK_RSYNC_LOG}
	# if we are the active index builder, rsync the html files
	BUILDER_HOST=$(find /local/jobs/updatedb/ -name heartbeat.json -exec cat {} \; | jq -r "select((.rsync_timestamp|tonumber) > now-120)|.hostname" | sort | head -n 1)
	if [ "${BUILDER_HOST}" = "$(hostname)" ]; then
		echo "$(date): active index updater, update index" >>${BACK_RSYNC_LOG}
		rsync -az -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --filter='merge /tmp/s5ci-idx-rsync-list' /local/jobs ${STORAGE_USER}@${STORAGE_HOST}: 2>>${BACK_RSYNC_LOG} >>${BACK_RSYNC_LOG}
	else
		echo "$(date): NOT an index updater (it is ${BUILDER_HOST}, not $(hostname))" >>${BACK_RSYNC_LOG}
	fi


	if [ -f /local/upstream-sync-exec ]; then
		bash -c /local/upstream-sync-exec >>${BACK_RSYNC_LOG}
	fi
done &

BACKSYNC_PID=$!


### sync the jobs from other hosts which were in a drain mode
cat <<__EE__ >/tmp/downstream-rsync-filter
include jobs
include jobs/updatedb
include jobs/updatedb/**
exclude jobs/updatedb/$(hostname)
exclude *
__EE__

while (true); do
	# rsync the list of updates, except our own 
	MY_HOST=$(hostname)
	echo "${MY_HOST} starting update from other hosts on $(date):" >>/local/logs/job-import.log
	rsync -avz -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --filter='merge /tmp/downstream-rsync-filter' ${STORAGE_USER}@${STORAGE_HOST}:${STORAGE_DIR} /local/ >"${INITIAL_RSYNC_LOG}" >>/local/logs/job-import.log
	echo "RSYNC ret code: $?" >>/local/logs/job-import.log
	for A_HOST in $(ls /local/jobs/updatedb); do
		if [ "$A_HOST" == "$MY_HOST" ]; then 
			echo not updating from ourselves
		else
			echo "${A_HOST} on $(date):" >>/local/logs/job-import.log
			JOB_IMPORT_LOG="/local/logs/job-import-$A_HOST.log"
			# rsync the list of jobs we know are maybe still sitting on other hosts
			echo "$(date): starting update from ${A_HOST}:" >>${JOB_IMPORT_LOG}
			RSYNC_FILTER_FILE="/local/jobs/updatedb/$A_HOST/rsync-filter.txt"
			RSYNC_FILTER="merge ${RSYNC_FILTER_FILE}"
			RSYNC_DB_FILTER_FILE="/local/jobs/updatedb/$A_HOST/rsync-db-filter.txt"
			RSYNC_DB_FILTER="merge ${RSYNC_DB_FILTER_FILE}"
			if [ -f /secrets/downstream-sync-skip.txt ]; then
				echo "$(date): /secrets/downstream-sync-skip.txt exists - skip host ${A_HOST}..." >>${JOB_IMPORT_LOG}
			else
				if [ -f ${RSYNC_DB_FILTER_FILE} ]; then
					rsync -avz -e 'ssh -p23 -i/secrets/s5ci-key' --recursive --max-delete=-1 --filter="$RSYNC_DB_FILTER" ${STORAGE_USER}@${STORAGE_HOST}:jobs/db /local/jobs/db 2>>${JOB_IMPORT_LOG} >>${JOB_IMPORT_LOG}
					echo "RSYNC ret code: $?" >>${JOB_IMPORT_LOG}
					# re-import the data from yaml files into the database
					go-s5ci -c ${S5CI_CONFIG_PATH} list-jobs -t 600 -n $(hostname) -u /local/jobs/db -y /local/jobs/updatedb/$A_HOST/updated-jobs.yaml 2>>${JOB_IMPORT_LOG} >>${JOB_IMPORT_LOG}
				else
					echo "${RSYNC_DB_FILTER_FILE} not found, skip import" >>${JOB_IMPORT_LOG}
				fi
			fi


		fi
	done
	if [ -f /local/downstream-sync-exec ]; then
		bash -c /local/downstream-sync-exec >>/local/logs/job-import.log
	fi
	echo "${MY_HOST} finished update from other hosts on $(date):" >>/local/logs/job-import.log
	while [ -f /secrets/downstream-sync-pause.txt ]; do
		echo "$(date): /secrets/downstream-sync-pause.txt exists - wait 30 sec..." >>${TIMELINE_LOG}
		sleep 30
	done
	sleep 5

done &
DRAINSYNC_PID=$!

#
# this part runs with signals intercepted, for cleanup
#


echo "$(date): EXECOK: S5CI startup finished, now run" >>${TIMELINE_LOG}

trap sigint INT
trap '' PIPE
trap '' HUP
trap cleanup QUIT
trap cleanup ABRT
trap cleanup TERM

sigint()
{
	echo "$(date): got SIGINT" >>${TIMELINE_LOG}
}

cleanup()
{
	echo "$(date): got SIGTERM" >>${TIMELINE_LOG}
        echo "Caught signal, cleaning up"
        echo "Done cleanup"
}

#
# blast away the update-db directory on the store, it will be recreated by active instances - this way less cruft for all.
mkdir /tmp/empty
rsync -avz --delete -e 'ssh -p23 -i/secrets/s5ci-key' --recursive /tmp/empty/ ${STORAGE_USER}@${STORAGE_HOST}:jobs/updatedb/

# execute the meta-s5ci
RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/go-s5ci -c ${META_S5CI_CONFIG_PATH} 2>>${META_S5CI_LOG} >>${META_S5CI_LOG} &

# execute the s5ci. 
RUST_LOG=debug RUST_BACKTRACE=1 /usr/local/bin/go-s5ci -c ${S5CI_CONFIG_PATH}

# stop syncing the html back and the root heartbeat
cat <<__EE__ >/local/back-sync-adjust-list
#!/bin/sh
sed -i -e '/\.html/d' -e '/include heartbeat.json/d' /tmp/s5ci-rsync-list
__EE__
chmod +x /local/back-sync-adjust-list

while true; do
	REMAINING_JOBS=$(ps -ef | grep run-job | grep -v grep | wc -l)
	if [ "$REMAINING_JOBS" = "0" ]; then
		echo "$(date): No remaining jobs running!" >>${TIMELINE_LOG}
		break
	fi
	echo "$(date): $REMAINING_JOBS jobs remain - wait 300 sec..." >>${TIMELINE_LOG}
	sleep 300
done

if [ -f /secrets/nomad-self-shutdown.txt ]; then
        echo "$(date): /secrets/nomad-self-shutdown.txt exists - wait 300 sec and stop our job..." >>${TIMELINE_LOG}
	sleep 300
	nomad stop ${NOMAD_JOB_NAME}
fi

# if instructed - wait
while [ -f /secrets/shutdown-pause.txt ]; do
        echo "$(date): /secrets/shutdown-pause.txt exists - wait 30 sec..." >>${TIMELINE_LOG}
	sleep 30
done

# kill the background sync
kill $BACKSYNC_PID
kill $DRAINSYNC_PID

while [ -f /secrets/final-shutdown-pause.txt ]; do
        echo "$(date): /secrets/final-shutdown-pause.txt exists - wait 30 sec..." >>${TIMELINE_LOG}
	sleep 30
done

# FIXME: re-add the "final rsync" here ?

# the empty cycle in the end
for i in $(seq 60 -1 1); do
	echo "$(date): winding down, $i sec remaining">>${TIMELINE_LOG}
	sleep 1
done

